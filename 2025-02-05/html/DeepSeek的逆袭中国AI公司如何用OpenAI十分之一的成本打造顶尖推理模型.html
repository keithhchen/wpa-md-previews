
<blockquote style="font-size: 14px; color: rgb(136, 136, 136);font-family: Optima-Regular, PingFangTC-light;">
<p>中国AI公司DeepSeek近期凭借其开源推理模型R1引发关注,该模型以极低的成本实现了与OpenAI o1相当的性能。在这期《YC Decoded》中,合伙人Diana Hu深入剖析了DeepSeek背后的核心技术优化,并将其置于近期AI突破的历史背景下,揭示了其独特创新。对于关注AI发展的专业人士,这不仅是一次技术解析,更是对未来趋势的前瞻思考。</p>
</blockquote>
<section id="highlights" style="border-radius: 20px; background: #fafafa; margin: 16px 8px; padding: 16px;font-family: Optima-Regular, PingFangTC-light;"><h2 style="font-size: 20px; color: rgb(21, 101, 192); font-weight: bold; margin: 16px 16px 8px;font-size: 14px; color: rgb(0, 0, 0);font-family: Optima-Regular, PingFangTC-light;">亮点</h2><ul style="margin-top: 16px; margin-bottom: 16px;font-family: Optima-Regular, PingFangTC-light;">
<li style="margin: 16px 0; font-size: 14px; line-height: 1.6;font-family: Optima-Regular, PingFangTC-light;">英伟达因深想科技发布R1模型,单日市值损失近6000亿美元。  </li>
<li style="margin: 16px 0; font-size: 14px; line-height: 1.6;font-family: Optima-Regular, PingFangTC-light;">深想科技V3模型采用8位浮点格式训练,最大生成吞吐量提升至5.76倍。  </li>
<li style="margin: 16px 0; font-size: 14px; line-height: 1.6;font-family: Optima-Regular, PingFangTC-light;">R1模型通过纯强化学习实现了顶级结果,无需人类或AI的外部示例。  </li>
<li style="margin: 16px 0; font-size: 14px; line-height: 1.6;font-family: Optima-Regular, PingFangTC-light;">V3模型的最终训练成本仅为550万美元,不包括研发和硬件运营费用。  </li>
<li style="margin: 16px 0; font-size: 14px; line-height: 1.6;font-family: Optima-Regular, PingFangTC-light;">伯克利实验室应用R1技术,仅花费30美元就生成了复杂推理的小型模型。</li>
</ul></section>

<h2 style="font-size: 20px; color: rgb(21, 101, 192); font-weight: bold; margin: 16px 16px 8px;font-family: Optima-Regular, PingFangTC-light;">DeepSeek R1:一个让OpenAI都颤抖的推理模型</h2><hr style="border-style: solid; border-width: 1px 0 0; border-color: rgba(0, 0, 0, 0.1); -webkit-transform-origin: 0 0; -webkit-transform: scale(1, 0.5); transform-origin: 0 0; transform: scale(1, 0.5);font-family: Optima-Regular, PingFangTC-light;"/>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">中国AI公司DeepSeek近期发布的R1模型无疑在全球AI领域投下了一颗重磅炸弹。这个开源的推理模型不仅在性能上对标OpenAI的o1,成本仅为后者的十分之一。消息一出,社交媒体迅速掀起热议,股市也随之震荡,Nvidia一天内市值蒸发600亿美元。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">对于紧密关注AI技术进展的人来说,DeepSeek和R1的出现并非毫无预兆。这家公司早在几个月前就已开始发布研究成果,并公开模型权重,走了一条与Meta的Lama模型相似的道路。与OpenAI、Google DeepMind、Anthropic等巨头不同,DeepSeek选择了更为开放的策略,在技术积累和公众关注之间找到了巧妙的平衡点。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">R1的发布不仅是一次技术突破,更是一场成本与效率的革命。通过一系列算法优化,特别是基于V3模型的底层改进,DeepSeek将推理能力提升到了新的高度。V3模型采用了8bit浮点格式训练,相比传统的16bit或32bit,大幅减少内存消耗,同时通过fp8累积修复技术,避免数值误差的累积。这种极致的效率优化让DeepSeek在硬件资源受限的情况下,依然能以更低的成本实现高性能的模型训练。这种“以小搏大”的策略不仅在技术上脱颖而出,更为整个AI行业树立了新标杆。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">R1的成功不仅在于技术突破,更在于对AI可及性的重新定义。作为一个开源模型,R1免费提供下载和本地运行,还为开发者提供了高度定制化空间。这种开放性和低成本让更多人能够参与到AI技术的应用中,进一步推动了AI从实验室走向实际场景的进程。DeepSeek的这一次“技术突围”不仅让OpenAI等巨头感受到压力,更为整个行业带来了新可能性。</p>
<h2 style="font-size: 20px; color: rgb(21, 101, 192); font-weight: bold; margin: 16px 16px 8px;font-family: Optima-Regular, PingFangTC-light;">DeepSeek的工程奇迹:为何R1如此高效?</h2><hr style="border-style: solid; border-width: 1px 0 0; border-color: rgba(0, 0, 0, 0.1); -webkit-transform-origin: 0 0; -webkit-transform: scale(1, 0.5); transform-origin: 0 0; transform: scale(1, 0.5);font-family: Optima-Regular, PingFangTC-light;"/>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">R1模型之所以能掀起波澜,核心在于其独特工程优化。采用8bit浮点运算格式相比传统16bit或32bit不仅大幅降低内存占用,还显著提升GPU利用率。通过FP8积累修复技术,进一步减少数值误差累积,确保训练过程中的计算精度,使数千块GPU的并行计算效率大幅提升,训练成本随之降低。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">另一个关键优化是混合专家架构(Mixture of Experts, MoE)。传统模型如Meta的Llama 3在每次推理时激活全部参数,而R1仅激活37亿参数中的一小部分,这种选择性激活使每次前向传播的计算量显著减少。结合MLA和MTP技术,R1在推理速度和生成质量上都达到了新高度。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">这些工程创新使R1在成本效益上占据明显优势,尤其在硬件资源受限环境下,通过深度优化,成功在高端GPU集群中实现近乎极限的性能释放。不仅为AI行业提供了高效解决方案,也为未来模型优化开辟了新方向。</p>
<h2 style="font-size: 20px; color: rgb(21, 101, 192); font-weight: bold; margin: 16px 16px 8px;font-family: Optima-Regular, PingFangTC-light;">混合物专家架构:DeepSeek的秘密武器</h2><hr style="border-style: solid; border-width: 1px 0 0; border-color: rgba(0, 0, 0, 0.1); -webkit-transform-origin: 0 0; -webkit-transform: scale(1, 0.5); transform-origin: 0 0; transform: scale(1, 0.5);font-family: Optima-Regular, PingFangTC-light;"/>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">V3的混合物专家架构是其高效推理的核心。不同于Lama 3模型每次推理激活405亿参数,V3仅激活37亿参数,节省了11倍运算量。这种设计不仅大幅降低计算成本,还保持模型高性能,使其在复杂推理任务中表现出色。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">混合物专家架构并非新概念,但DeepSeek的创新在于稳定性与效率的平衡。通过优化GPU利用率,V3在处理大规模数据时仍能保持高效运行。这种架构使DeepSeek在有限硬件资源下,仍能实现与顶级模型相媲美的推理速度,为大规模AI应用提供了可行解决方案。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">这一技术突破展示了在现有硬件条件下,通过软件优化可显著提升AI模型的推理效率。不仅为AI领域的技术进步提供了新思路,也为更多企业和开发者提供了经济高效的AI工具,推动了AI技术在各行业的普及与应用。</p>
<h2 style="font-size: 20px; color: rgb(21, 101, 192); font-weight: bold; margin: 16px 16px 8px;font-family: Optima-Regular, PingFangTC-light;">多头潜在注意力机制:KV缓存问题的终极解决方案</h2><hr style="border-style: solid; border-width: 1px 0 0; border-color: rgba(0, 0, 0, 0.1); -webkit-transform-origin: 0 0; -webkit-transform: scale(1, 0.5); transform-origin: 0 0; transform: scale(1, 0.5);font-family: Optima-Regular, PingFangTC-light;"/>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">在AI模型的推理过程中,KV缓存(Key-Value Cache)一直是内存开销的主要来源之一。传统注意力机制需要存储完整键值矩阵,不仅占用大量内存,还限制了模型的生成吞吐量。V2模型引入的多头潜在注意力机制(MLA)彻底改变了这一局面。通过将键值矩阵压缩为潜在表示,并在需要时动态重构,MLA成功将KV缓存大小减少了93.3%。这一优化不仅大幅降低内存占用,还将最大生成吞吐量提升了5.76倍。对于大规模模型来说,MLA不仅解决了内存瓶颈,还显著提高了推理效率,为AI模型的轻量化部署提供了新可能性。</p>
<h2 style="font-size: 20px; color: rgb(21, 101, 192); font-weight: bold; margin: 16px 16px 8px;font-family: Optima-Regular, PingFangTC-light;">强化学习的魔力:DeepSeek如何训练出思考型AI</h2><hr style="border-style: solid; border-width: 1px 0 0; border-color: rgba(0, 0, 0, 0.1); -webkit-transform-origin: 0 0; -webkit-transform: scale(1, 0.5); transform-origin: 0 0; transform: scale(1, 0.5);font-family: Optima-Regular, PingFangTC-light;"/>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">R1模型通过强化学习技术展现了AI在推理能力上的新突破。与传统语言模型不同,R1被设计为专门处理复杂问题,能逐步拆解并思考问题,甚至在中途发现错误时进行自我修正。这种能力的关键在于DeepSeek采用的强化学习框架——Group RPO(Group Relative Policy Optimization)。通过这一技术,R1在训练中并不依赖人类或AI提供的思维范例,而是完全通过自身生成的反馈进行优化,最终实现了在数学和编程基准测试中的优异表现,与OpenAI的o1模型不相上下。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">R1的成功不仅体现了强化学习在AI推理领域的潜力,也揭示了DeepSeek在算法创新上的独特之处。尽管R1的早期版本在推理过程中存在语言混杂的问题,DeepSeek通过引入冷启动阶段,对模型进行了微调,使输出更加连贯和可读。这一改进不仅提升模型的实际应用价值,也为未来AI研究提供了新思路。从AlphaGo到R1,强化学习正逐步从游戏领域扩展到更广泛的问题求解场景,展现其强大的适应性和潜力。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">值得注意的是,R1的表现并非一蹴而就,而是基于DeepSeek此前在模型效率优化上的多年积累。通过结合多令牌预测、注意力机制压缩等技术,R1在推理效率上取得了显著提升。这种高效的训练和推理框架使R1能在较低成本下实现接近顶尖模型的表现,为AI行业提供了极具参考价值的案例。</p>
<h2 style="font-size: 20px; color: rgb(21, 101, 192); font-weight: bold; margin: 16px 16px 8px;font-family: Optima-Regular, PingFangTC-light;">DeepSeek的未来影响:AI成本将持续下降</h2><hr style="border-style: solid; border-width: 1px 0 0; border-color: rgba(0, 0, 0, 0.1); -webkit-transform-origin: 0 0; -webkit-transform: scale(1, 0.5); transform-origin: 0 0; transform: scale(1, 0.5);font-family: Optima-Regular, PingFangTC-light;"/>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">DeepSeek的成功不仅是一个技术突破,更是一个信号:AI领域的创新空间仍然巨大。通过将FP8浮点格式与混合专家架构(MoE)结合,大幅降低了计算成本,同时保持模型性能。这种技术突破不仅是为了在竞争中领先,更是为了推动AI应用的普及。随着训练和推理成本的持续下降,更多企业和开发者将能够以更低门槛进入AI领域,创造出更多具有实际价值的应用。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">DeepSeek的模型R1不仅在性能上媲美OpenAI的o1,其开源和低成本特性进一步降低进入门槛。这种趋势预示着,未来AI技术的规模化应用将不再被高昂成本限制。从消费者端的智能助手到企业级的数据分析平台,AI的成本下降将直接推动更多创新场景的落地。可以说,DeepSeek的成功不仅是一次技术胜利,更是整个AI行业进入普惠阶段的重要标志。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;">此外,DeepSeek的技术路线还揭示了AI领域的一个关键趋势:堆栈的重新构建。通过从底层硬件到软件工具链的全面优化,DeepSeek展示了如何在有限的资源下实现更高效率。这种思路不仅适用于AI模型的训练和推理,也可以为其他计算密集型领域提供借鉴。随着越来越多的公司加入到这一技术竞赛中,AI应用的成本将进一步降低,技术创新的速度也将持续加快。正如业内人士所预言的,未来几年将是AI应用爆发式增长的关键时期。</p>
<p style="font-size: 16px; margin: 16px 16px 24px; line-height: 1.75em;font-family: Optima-Regular, PingFangTC-light;"><em>原链接:https://www.youtube.com/watch?v=4Tmn-XP93m4</em></p><section style="text-align: center;margin-left: 16px;margin-right: 16px;font-family: Optima-Regular, PingFangTC-light;"><img alt="图片" class="rich_pages wxw-img" crossorigin="anonymous" data-fail="0" data-type="jpeg" src="https://mmbiz.qpic.cn/mmbiz_jpg/ddoFEEahZice8askrD1Oe0v74LO9QiaiaDaaiabQdYgXicD7oP0jyia370MgjQhicJcHuVSNOtNiaHWTNkFiaIQrlNhFmMA/640?wx_fmt=jpeg&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" style="width: 100%; height: auto;font-family: Optima-Regular, PingFangTC-light;"/></section>
<section style="text-align: center;background-color: rgb(255, 255, 255);line-height: 1.75em;margin-top: 24px;margin-bottom: 24px;margin-left: 16px;margin-right: 16px;font-family: Optima-Regular, PingFangTC-light;"><span style="color: rgb(0, 0, 0);font-family: Optima-Regular, PingFangTC-light;font-size: 36px;font-family: Optima-Regular, PingFangTC-light;">💬</span></section><section style="text-align: center;background-color: rgb(255, 255, 255);line-height: 1.75em;margin-bottom: 24px;margin-left: 16px;margin-right: 16px;font-family: Optima-Regular, PingFangTC-light;"><span style="color: rgb(0, 0, 0);font-family: Optima-Regular, PingFangTC-light;letter-spacing: 1px;font-size: 14px;font-family: Optima-Regular, PingFangTC-light;">如果你也是未来领域的关注者，请留言你的回声</span></section>