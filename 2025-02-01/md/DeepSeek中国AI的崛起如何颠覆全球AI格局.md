# DeepSeek:中国AI的崛起如何颠覆全球AI格局?

>在AI领域风起云涌的今天,DeepSeek异军突起,迅速占领了全球头条和应用商店的榜首,甚至超越了OpenAI的ChatGPT。在这期特辑中,TechCrunch邀请了加州大学伯克利分校计算机科学教授、Databricks联合创始人Ion Stoica,深度探讨了DeepSeek的崛起背后的关键因素:开源的未来、微软Azure的支持、美国创新政策的走向,以及围绕其模型训练的争议。专业人士的洞见与行业的剧烈变革交织,为AI领域的未来提供了极具启发性的思考。

## 亮点
- 深度求索(DeepSeek)的模型激活的神经元比例仅为5.5%,远低于GPT-4的12.5%到25%。  
- 深度求索使用8位而不是16位进行训练,优化了通信效率并显著降低成本。  
- 微软宣布将在Azure上托管深度求索的模型,以避免与中国相关的数据和流量问题。  
- 深度求索的开源模型在性能和效率上超越了OpenAI的ChatGPT,并成为应用商店的榜首。  
- 深度求索通过强化学习在推理任务上取得了显著进展,尤其是在数学和编程领域。

## DeepSeek击败ChatGPT,成为应用商店的霸主
DeepSeek的崛起无疑让全球AI领域重新洗牌。这款由中国AI实验室开发的聊天机器人,不仅在短时间内超越了OpenAI的ChatGPT,更是迅速登顶应用商店的榜首,成为全球用户的首选AI应用。其成功基于一系列技术突破和高效的模型优化。DeepSeek不仅在多项基准测试中表现出色,还在实际应用中展现了极高的推理能力和效率,尤其是在语言模型评估平台Chatbot Arena中位列前三。其开源属性为其赢得了广泛的支持,进一步加速了技术迭代和社区贡献。

微软的Azure平台托管DeepSeek的模型,既是对其技术实力的认可,也是对市场需求的直接回应。这一决策不仅缓解了数据安全和隐私方面的担忧,也为全球用户提供了更便捷的访问渠道。DeepSeek的成功不仅是单一企业的胜利,更是开源生态和全球协作的胜利,预示着未来AI发展的新方向。

关于DeepSeek是否使用了OpenAI的模型进行训练的争议仍在发酵。尽管OpenAI声称有证据表明DeepSeek“蒸馏”了其模型,但DeepSeek在效率和创新方面的显著进步,尤其是其混合专家模型(MoE)和低比特训练技术的应用,表明其技术路径具有独特性和自主性。这场争议背后,实则是关于技术创新、开源文化和全球竞争的深刻讨论。无论是OpenAI还是DeepSeek,都在推动AI技术的前沿,而最终的受益者,显然将是整个行业和全球用户。

## 开源还是闭源?DeepSeek的选择引发AI界大讨论
DeepSeek的开源模式与OpenAI的闭源策略形成了鲜明对比。UC Berkeley的Ion Stoica教授表示,开源是AI未来的发展方向。他认为,开源不仅能够加速技术进步,还能让更多人和机构参与到AI的迭代和优化中,形成良性循环。相比之下,封闭的研发模式虽然在短期内保持技术优势,但长期的创新动力会受到限制。

Stoica指出,开源模式的另一大优势在于其透明性和可验证性。通过公开模型权重、训练数据和算法,研究人员可以更全面地理解模型的性能和局限,从而推动AI技术的安全性和可靠性。这种开放性不仅有助于学术界的研究,也能为工业界提供更多的技术支持和创新灵感。

尽管开源模式面临挑战,尤其是在涉及敏感数据和知识产权时,如何找到平衡仍需谨慎处理。Stoica坚信,推动更多的开源项目和技术共享,将是未来AI领域持续创新和竞争的关键。

## 微软为何选择在Azure上托管DeepSeek?
微软决定在Azure上托管DeepSeek的模型,这一举动颇具战略眼光。一方面,它让DeepSeek的模型更容易被全球企业快速接入和使用,尤其是在Azure的庞大生态系统支持下,企业可以通过熟悉的平台无缝集成AI能力。另一方面,这一安排也巧妙地规避了数据流向中国的潜在风险。由于数据的处理和服务部署都在Azure的数据中心内完成,企业和用户不再需要担心数据跨境传输带来的隐私和安全问题。这一决策不仅体现了微软对市场需求和监管环境的敏锐洞察,也为企业客户提供了一个更可靠的选择。从技术角度来看,Azure的全球覆盖和高性能计算资源也为DeepSeek模型的稳定性和效率提供了强有力的保障。

## DeepSeek的模型效率惊人,芯片制造商慌了?
DeepSeek的模型效率达到了惊人的5.5%,这一数字远低于其他主流模型的神经元激活率,如GPT-4的12.5%或25%。这种极低激活率的背后,是DeepSeek在技术上的一系列突破,包括使用8位而非16位精度进行训练,优化通信效率等。这些技术创新显著降低了计算成本,同时也引发了芯片制造商的担忧:如果模型效率继续提升,未来是否还需要庞大的计算集群?尽管有观点认为,效率提升将刺激市场需求,但不可否认的是,芯片行业正面临深刻变革。DeepSeek的崛起,不仅改变了AI模型的竞争格局,也对硬件生态提出了新的挑战。

## DeepSeek是否抄袭了OpenAI?AI界的‘抄袭门’真相揭秘
最近,AI界的“抄袭门”成了热议话题。OpenAI公开指责DeepSeek使用了他们的模型进行训练,但这番指控在业内引发了截然不同的反应。UC伯克利的计算机科学教授Ion Stoica对此持怀疑态度,他认为OpenAI的指控缺乏实质证据,更多是源于竞争对手的焦虑与不安。Stoica提到,DeepSeek的模型架构与OpenAI完全不同,尤其是在混合专家模型(Mixture of Experts)的设计上,DeepSeek展现了更高的效率,激活的神经元比例仅为5.5%,远低于OpenAI的12.5%。这种技术上的突破,很难简单归因于“抄袭”。

Stoica进一步指出,即便DeepSeek使用了OpenAI的部分数据,这也是行业内常见现象,而非决定性的技术优势。更重要的是,DeepSeek的模型已经开源,任何人都可以验证其性能与效率。随着微软将其模型部署在Azure上,DeepSeek的技术实力得到了市场的认可。这场“抄袭门”背后,或许是AI巨头之间的竞争焦虑,以及对开源模式的不适应。Stoica强调,与其将精力放在指责他人,不如聚焦于如何加速自身的创新。开源与透明,才是推动行业进步的关键。

## AI创新已触顶?DeepSeek的技术突破告诉我们什么?
有人认为AI创新已经达到瓶颈,DeepSeek的技术突破却打破了这种看法,尤其在推理任务上的表现令人瞩目。DeepSeek通过优化模型效率,将推理任务中的神经元激活率降至5.5%,远低于行业常见的12.5%到25%,显著提升了模型的计算效率。这种技术并非全新架构,但其在现有技术基础上的整合与优化,实现了显著的性能提升。DeepSeek的成功表明,AI领域仍有巨大的发展空间,尤其是在需要验证输出的任务上,如数学问题和代码生成,未来的突破将进一步加速。

## 详细对话
Max Zeff: 今天我们将深入探讨DeepSeek,这家中国AI实验室最近在新闻和应用商店中引起了巨大轰动,甚至超越了OpenAI的ChatGPT。我将与UC Berkeley的计算机科学教授Ion Stoica一起讨论这一切。

Ion Stoica: 非常感谢你的邀请,Max。

Max Zeff: 首先,我想请你快速帮我们区分一下事实与炒作,DeepSeek最近的模型有哪些真正的突破,哪些是过度炒作的?

Ion Stoica: 我认为有三个事实是显而易见的。首先,它在基准测试中表现非常出色,尤其是在我们的chbo Arena上。其次,DeepSeek的模型在查询服务上非常高效。第三,它是开源的。这些点显然是推动了这一波热潮的原因。

Max Zeff: 你提到了它的效率提升,但我很好奇这对芯片制造商意味着什么?有人认为这些效率提升意味着我们不再需要大规模的计算集群了,你能解释一下这个论点吗?

Ion Stoica: 我认为恰恰相反,降低成本会刺激需求,加速AI在企业和行业中的采用。我们已经从OpenAI的数据中看到了这一点,成本的降低推动了收入的爆炸性增长。

Max Zeff: 你对开源与闭源之间的拉锯战怎么看?DeepSeek的模型是开源的,你觉得这对AI领域意味着什么?

Ion Stoica: 我是开源的坚定支持者。开源加速了进展,因为它提供了一个共同的基础,每个人都可以在此基础上进行改进。我认为,美国的AI发展在过去几年中陷入了各自为战的局面,Meta是个例外,而学术界由于资源匮乏,几乎被排除在外。

Max Zeff: 你对微软在Azure上托管DeepSeek的决定怎么看?

Ion Stoica: 这从商业角度来看是合理的。微软此举避免了数据流向中国的潜在风险,同时也是对DeepSeek性能的认可。

Max Zeff: OpenAI声称DeepSeek使用了他们的模型进行训练,你觉得这种指控有道理吗?

Ion Stoica: 我认为这种指控缺乏实质证据。虽然在训练数据上可能会有一些重叠,但DeepSeek在模型效率和稳定性上的进步是明显的,这些是无法通过简单的“抄袭”实现的。

Max Zeff: 几个月前,我们还在讨论AI进展是否已经触及天花板,你觉得DeepSeek的技术突破对AI的未来意味着什么?

Ion Stoica: 我认为在某些任务上,尤其是可以通过验证得出结果的任务上,AI还有巨大的发展空间。DeepSeek在推理任务上的出色表现证明了这一点。未来,我们会在更多的任务中看到类似的进步。

_原链接:https://www.youtube.com/watch?v=P0apr-SIZW8_